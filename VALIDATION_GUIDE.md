# Guia de Valida√ß√£o - Printer Queue Service

Guia completo para validar todas as features implementadas do sistema.

## üìã Vis√£o Geral

Este guia cobre a valida√ß√£o de:
- **Fase 1:** Funda√ß√£o (API + Worker + Database) ‚úÖ
- **Fase 2:** Storage Drivers + Reindexa√ß√£o de Assets ‚úÖ
- **Fase 3:** Ingest√£o de Picklist e Pipeline de Jobs ‚úÖ
- **Fase 4:** Dimensionamento, Layout e Renderiza√ß√£o de PDFs ‚úÖ

---

## ‚öôÔ∏è Pr√©-requisitos

- Docker instalado (vers√£o 20.10+)
- Docker Compose instalado (vers√£o 2.0+)
- Terminal/Shell
- curl ou similar para testar APIs

---

## üöÄ Setup Inicial Completo

### 1. Criar arquivo .env

```bash
cd /path/to/printer-queue-service

cat > .env << 'EOF'
# Database
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=printer_queue
POSTGRES_PASSWORD=changeme
POSTGRES_DB=printer_queue_db

# Redis
REDIS_URL=redis://redis:6379/0

# API
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true
API_WORKERS=1

# Worker
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# Security
SECRET_KEY=changeme-use-a-secure-random-key-in-production
STORAGE_ENCRYPTION_KEY=changeme-32-bytes-base64-encoded-key

# Environment
ENVIRONMENT=development
EOF
```

### 2. Build e Iniciar Servi√ßos

```bash
# Build containers
docker-compose build

# Iniciar todos os servi√ßos
docker-compose up -d

# Aguardar servi√ßos subirem
sleep 15
```

**Verificar status:**
```bash
docker-compose ps
```

Todos os servi√ßos devem estar "Up":
- printer_queue_postgres
- printer_queue_redis
- printer_queue_api
- printer_queue_worker

### 3. Executar Migrations

```bash
docker-compose run --rm api alembic upgrade head
```

**Esperado:** Migrations executam sem erros.

### 4. Executar Seeds

```bash
docker-compose run --rm api python -m app.db.seed
```

**Esperado:**
```
Created tenant: Demo Tenant (ID: 1)
Created machine: Demo DTF Printer
Created sizing profile: P (80.0mm)
Created sizing profile: M (100.0mm)
Created sizing profile: G (120.0mm)
Created sizing profile: GG (140.0mm)
Created storage config: local at /tmp/printer-queue-assets/tenant-1
‚úì Database seeded successfully!
```

---

## ‚úÖ FASE 1 - Funda√ß√£o (Valida√ß√£o)

### Resumo da Fase 1

**Entregue:**
- API FastAPI com endpoints base
- Worker Celery operacional
- 8 tabelas no banco (tenants, machines, storage_configs, assets, jobs, job_items, sizing_profiles)
- Extens√£o pg_trgm habilitada
- Docker Compose com 4 servi√ßos
- CI/CD b√°sico
- Documenta√ß√£o completa

**Endpoints dispon√≠veis:**
- `GET /health` - Health check completo
- `GET /v1/healthz` - Health check simples
- `GET /v1/tenants` - Lista tenants

---

### Crit√©rios de Aceite - Fase 1

### Feature 1: Base do projeto

#### ‚úÖ Crit√©rio 1: docker-compose up sobe todos os servi√ßos sem erros

**Valida√ß√£o:**
```bash
docker-compose up --build
```

**Resultado esperado:**
- Postgres: container rodando
- Redis: container rodando
- API: container rodando
- Worker: container rodando
- Sem erros nos logs

**Como verificar:**
```bash
docker-compose ps
```

Deve mostrar 4 servi√ßos com status "Up".

---

#### ‚úÖ Crit√©rio 2: curl http://localhost:8000/health retorna 200

**Valida√ß√£o:**
```bash
curl http://localhost:8000/health
```

**Resultado esperado:**
```json
{
  "status": "ok",
  "db": "connected",
  "redis": "connected"
}
```

**Status HTTP:** 200

---

#### ‚úÖ Crit√©rio 3: Worker conecta no Redis e fica aguardando tarefas

**Valida√ß√£o:**
```bash
docker-compose logs worker
```

**Resultado esperado:**
- Logs mostram: `celery@<hostname> ready.`
- Worker n√£o crashou
- Conectado ao Redis

**Exemplo de log esperado:**
```
[INFO/MainProcess] Connected to redis://redis:6379/0
[INFO/MainProcess] celery@abc123 ready.
```

---

#### ‚úÖ Crit√©rio 4: CI roda com sucesso

**Valida√ß√£o:**
- Fazer commit e push do c√≥digo
- Verificar GitHub Actions

**Resultado esperado:**
- Todos os jobs passam (lint, test, migrations)
- Checks ficam verdes

**Nota:** Este crit√©rio ser√° validado ap√≥s o push para o reposit√≥rio.

---

#### ‚úÖ Crit√©rio 5: README cont√©m instru√ß√µes claras de setup

**Valida√ß√£o:**
```bash
cat README.md
```

**Resultado esperado:**
- Instru√ß√µes de setup local
- Como subir com Docker
- Como executar migrations
- Como executar seeds
- Como validar

---

### Feature 2: Banco de dados

#### ‚úÖ Crit√©rio 6: Extens√£o pg_trgm est√° habilitada

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "SELECT * FROM pg_extension WHERE extname = 'pg_trgm';"
```

**Resultado esperado:**
```
 oid  | extname | extowner | extnamespace | extrelocatable | extversion | extconfig | extcondition 
------+---------+----------+--------------+----------------+------------+-----------+--------------
 xxxx | pg_trgm |       10 |           xx | t              | 1.6        |           | 
```

Deve retornar **1 linha** mostrando a extens√£o pg_trgm.

---

#### ‚úÖ Crit√©rio 7: Todas as 8 tabelas existem ap√≥s migrations

**Primeiro, executar migrations:**
```bash
docker-compose run --rm api alembic upgrade head
```

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "\dt"
```

**Resultado esperado:**
```
                      List of relations
 Schema |          Name          | Type  |     Owner      
--------+------------------------+-------+----------------
 public | assets                 | table | printer_queue
 public | job_items              | table | printer_queue
 public | jobs                   | table | printer_queue
 public | machines               | table | printer_queue
 public | sizing_profiles        | table | printer_queue
 public | tenant_storage_configs | table | printer_queue
 public | tenants                | table | printer_queue
(8 rows)
```

**Total:** 8 tabelas

---

#### ‚úÖ Crit√©rio 8: Seeds criam 1 tenant, 1 machine, 4 sizing_profiles

**Executar seeds:**
```bash
docker-compose run --rm api python -m app.db.seed
```

**Valida√ß√£o 1 - Tenant:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "SELECT id, name, is_active FROM tenants;"
```

**Resultado esperado:**
```
 id |    name     | is_active 
----+-------------+-----------
  1 | Demo Tenant | t
(1 row)
```

**Valida√ß√£o 2 - Machine:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "SELECT id, name, max_width_mm, max_length_mm, min_dpi FROM machines;"
```

**Resultado esperado:**
```
 id |      name        | max_width_mm | max_length_mm | min_dpi 
----+------------------+--------------+---------------+---------
  1 | Demo DTF Printer |          600 |          2500 |     300
(1 row)
```

**Valida√ß√£o 3 - Sizing Profiles:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "SELECT id, size_label, target_width_mm FROM sizing_profiles ORDER BY target_width_mm;"
```

**Resultado esperado:**
```
 id | size_label | target_width_mm 
----+------------+-----------------
  1 | P          |              80
  2 | M          |             100
  3 | G          |             120
  4 | GG         |             140
(4 rows)
```

---

#### ‚úÖ Crit√©rio 9: Query retorna dados dos seeds

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "SELECT * FROM tenants;"
```

**Resultado esperado:**
- Retorna **1 linha** com o tenant "Demo Tenant"

---

#### ‚úÖ Crit√©rio 10: √çndice trigram existe em assets.sku_normalized

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "\d+ assets"
```

**Resultado esperado:**
Deve mostrar √≠ndices incluindo:
```
Indexes:
    "assets_pkey" PRIMARY KEY, btree (id)
    "idx_assets_sku_normalized_trgm" gin (sku_normalized gin_trgm_ops)
    "ix_assets_id" btree (id)
    "ix_assets_sku_normalized" btree (sku_normalized)
    "ix_assets_tenant_id" btree (tenant_id)
```

O √≠ndice **idx_assets_sku_normalized_trgm** deve estar presente.

---

## ‚úÖ FASE 3 - Ingest√£o de Picklist e Pipeline (Valida√ß√£o)

### Resumo da Fase 3

**Entregue:**
- Feature 5: Upload de picklist PDF e cria√ß√£o de job
- Feature 6: Parsing de PDF com Docling
- Feature 7: Resolu√ß√£o de SKUs com fuzzy matching
- Fluxo de resolu√ß√£o manual para SKUs amb√≠guos/missing
- 6 novos endpoints REST
- 2 novos servi√ßos (PDFParserService, SKUResolverService)
- 11 schemas Pydantic para jobs
- 1 migration (mode + sizing_profile_id)

**Endpoints dispon√≠veis:**
- `POST /v1/jobs` - Upload picklist e criar job
- `GET /v1/jobs` - Listar jobs
- `GET /v1/jobs/{id}` - Detalhes do job
- `DELETE /v1/jobs/{id}` - Deletar job
- `GET /v1/jobs/{id}/pending-items` - Items pendentes
- `POST /v1/jobs/{id}/resolve` - Resolver items manualmente

---

### Pr√©-requisitos para Fase 3

Antes de validar a Fase 3, certifique-se de que:

```bash
# 1. Aplicar nova migration
docker-compose run --rm api alembic upgrade head

# 2. Rebuild worker com Docling
docker-compose build worker
docker-compose up -d worker

# 3. Verificar worker reiniciou
docker-compose logs worker | tail -20
```

**Esperado:** Worker deve mostrar `celery@<hostname> ready.`

---

### Feature 5: Upload de Picklist e Cria√ß√£o de Job

#### ‚úÖ Crit√©rio 1: Endpoint POST /v1/jobs aceita multipart/form-data

**Prepara√ß√£o - Criar PDF de teste:**
```bash
# Op√ß√£o 1: Usar script
python3 scripts/create-test-picklist.py -o test_picklist.pdf

# Op√ß√£o 2: Usar qualquer PDF de teste
```

**Valida√ß√£o:**
```bash
curl -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 1" \
  -F "file=@test_picklist.pdf" \
  -F "mode=sequence" \
  -F "machine_id=1"
  # sizing_profile_id √© OPCIONAL - usa auto-matching por SKU prefix
```

**Nota:** O par√¢metro `sizing_profile_id` √© opcional. Se omitido, o sistema faz **auto-matching** baseado no prefixo do SKU de cada item (ver Feature 8 para detalhes).

**Resultado esperado:**
```json
{
  "id": 1,
  "status": "queued",
  "mode": "sequence",
  "picklist_uri": "tenant/1/picklists/1.pdf",
  "created_at": "2026-01-15T10:00:00Z"
}
```

**Status HTTP:** 201 Created

---

#### ‚úÖ Crit√©rio 2: PDF √© salvo no storage configurado

**Valida√ß√£o (para local storage):**
```bash
ls -lh /tmp/printer-queue-assets/tenant-1/picklists/
```

**Resultado esperado:**
```
-rw-r--r-- 1 user user 8.5K Jan 15 10:00 1.pdf
```

O arquivo `1.pdf` (ou n√∫mero do job) deve existir.

**Para S3:**
```bash
# Verificar no bucket S3 configurado
# Caminho: tenant/1/picklists/1.pdf
```

---

#### ‚úÖ Crit√©rio 3: Job √© criado com status "queued"

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, status, mode, picklist_uri FROM jobs;"
```

**Resultado esperado:**
```
 id | status | mode     | picklist_uri                 
----+--------+----------+------------------------------
  1 | queued | sequence | tenant/1/picklists/1.pdf
(1 row)
```

---

#### ‚úÖ Crit√©rio 4: Worker task √© enfileirada

**Valida√ß√£o:**
```bash
# Ver logs do worker
docker-compose logs worker | grep "process_job"
```

**Resultado esperado:**
```
[INFO] Starting job processing for job_id=1
```

---

#### ‚úÖ Crit√©rio 5: Listagem de jobs funciona

**Valida√ß√£o:**
```bash
curl "http://localhost:8000/v1/jobs?page=1&size=10" \
  -H "X-Tenant-ID: 1"
```

**Resultado esperado:**
```json
{
  "items": [
    {
      "id": 1,
      "status": "queued",
      "mode": "sequence",
      "picklist_uri": "tenant/1/picklists/1.pdf",
      "items_count": 0,
      "created_at": "2026-01-15T10:00:00Z",
      "updated_at": "2026-01-15T10:00:00Z"
    }
  ],
  "total": 1,
  "page": 1,
  "size": 10,
  "pages": 1
}
```

---

#### ‚úÖ Crit√©rio 6: Valida√ß√£o impede upload sem storage configurado

**Valida√ß√£o (criar tenant sem storage):**
```bash
# Criar tenant de teste sem storage
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "INSERT INTO tenants (name, is_active, created_at, updated_at) VALUES ('No Storage Tenant', true, NOW(), NOW());"

# Tentar upload
curl -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 2" \
  -F "file=@test_picklist.pdf" \
  -F "mode=sequence" \
  -F "machine_id=1"
```

**Resultado esperado:**
```json
{
  "detail": "Tenant does not have storage configured"
}
```

**Status HTTP:** 400 Bad Request

---

#### ‚úÖ Crit√©rio 7: Valida√ß√£o impede upload de arquivos > 10MB

**Valida√ß√£o:**
```bash
# Criar arquivo grande (11MB)
dd if=/dev/zero of=large_file.pdf bs=1M count=11

# Tentar upload
curl -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 1" \
  -F "file=@large_file.pdf" \
  -F "mode=sequence" \
  -F "machine_id=1"

# Limpar
rm large_file.pdf
```

**Resultado esperado:**
```json
{
  "detail": "File too large: 11.00MB (max 10MB)"
}
```

**Status HTTP:** 413 Request Entity Too Large

---

### Feature 6: Parsing com Docling

#### ‚úÖ Crit√©rio 8: Worker baixa PDF do storage corretamente

**Valida√ß√£o:**
```bash
# Aguardar processamento (10 segundos)
sleep 10

# Ver logs do worker
docker-compose logs worker | grep "Downloading PDF"
```

**Resultado esperado:**
```
[INFO] Downloading PDF from tenant/1/picklists/1.pdf
```

---

#### ‚úÖ Crit√©rio 9: Docling extrai items do PDF

**Valida√ß√£o:**
```bash
docker-compose logs worker | grep "Parsed.*items from PDF"
```

**Resultado esperado:**
```
[INFO] Parsed 7 items from PDF
```

(O n√∫mero varia conforme o PDF)

---

#### ‚úÖ Crit√©rio 10: Raw extraction √© salvo em manifest_json

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT manifest_json FROM jobs WHERE id = 1;" | head -20
```

**Resultado esperado:**
```json
{
  "raw_extraction": [
    {"sku": "CAMISA-AZUL", "quantity": 5, "size_label": "P"},
    {"sku": "SHORT-VERMELHO", "quantity": 3, "size_label": "M"}
  ],
  "parsed_at": "2026-01-15T10:00:05Z",
  "item_count": 7
}
```

---

#### ‚úÖ Crit√©rio 11: Job items s√£o criados em job_items

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, job_id, sku, quantity, size_label, status FROM job_items WHERE job_id = 1;"
```

**Resultado esperado:**
```
 id | job_id | sku             | quantity | size_label | status  
----+--------+-----------------+----------+------------+---------
  1 |      1 | CAMISA-AZUL     |        5 | P          | pending
  2 |      1 | SHORT-VERMELHO  |        3 | M          | pending
  3 |      1 | CALCA-PRETA     |       10 | G          | pending
...
```

---

#### ‚úÖ Crit√©rio 12: Job status muda para "processing"

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, status FROM jobs WHERE id = 1;"
```

**Resultado esperado (durante processamento):**
```
 id | status     
----+------------
  1 | processing
```

---

#### ‚úÖ Crit√©rio 13: Erros de parsing marcam job como "failed"

**Valida√ß√£o (PDF corrompido):**
```bash
# Criar PDF inv√°lido
echo "Not a PDF" > invalid.pdf

# Upload
curl -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 1" \
  -F "file=@invalid.pdf" \
  -F "mode=sequence" \
  -F "machine_id=1"

# Aguardar processamento
sleep 5

# Verificar status
JOB_ID=2  # Ajustar conforme necess√°rio
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, status, manifest_json FROM jobs WHERE id = $JOB_ID;"
```

**Resultado esperado:**
```
 id | status | manifest_json                          
----+--------+----------------------------------------
  2 | failed | {"error": "Failed to parse PDF: ..."}
```

---

### Feature 7: Resolu√ß√£o de SKUs

#### ‚úÖ Crit√©rio 14: SKUs s√£o normalizados (uppercase, trim)

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT sku FROM job_items WHERE job_id = 1 LIMIT 3;"
```

**Resultado esperado:**
```
      sku       
----------------
CAMISA-AZUL
SHORT-VERMELHO
CALCA-PRETA
```

Todos devem estar em **UPPERCASE** sem espa√ßos extras.

---

#### ‚úÖ Crit√©rio 15: Match exato encontra assets corretamente

**Prepara√ß√£o - Criar asset com SKU exato:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "INSERT INTO assets (tenant_id, sku_normalized, original_filename, file_uri, created_at, updated_at) VALUES (1, 'CAMISA-AZUL', 'camisa-azul.png', 'tenant/1/assets/camisa-azul.png', NOW(), NOW());"

# Processar novo job
curl -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 1" \
  -F "file=@test_picklist.pdf" \
  -F "mode=sequence" \
  -F "machine_id=1"

# Aguardar
sleep 10
```

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT sku, status, asset_id FROM job_items WHERE sku = 'CAMISA-AZUL' ORDER BY id DESC LIMIT 1;"
```

**Resultado esperado:**
```
     sku      | status   | asset_id 
--------------+----------+----------
CAMISA-AZUL   | resolved |        1
```

---

#### ‚úÖ Crit√©rio 16: Match fuzzy com score > 0.7 resolve automaticamente

**Prepara√ß√£o - Criar asset similar:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "INSERT INTO assets (tenant_id, sku_normalized, original_filename, file_uri, created_at, updated_at) VALUES (1, 'CAMISA-AZUL-MARINHO', 'camisa-azul-marinho.png', 'tenant/1/assets/camisa.png', NOW(), NOW());"
```

**Valida√ß√£o:**
```bash
# Ver logs de resolu√ß√£o
docker-compose logs worker | grep "Fuzzy match resolved"
```

**Resultado esperado:**
```
[INFO] Fuzzy match resolved: CAMISA-AZUL-MARINHO (asset_id=2, score=0.850)
```

---

#### ‚úÖ Crit√©rio 17: SKUs n√£o encontrados marcam item como "missing"

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT sku, status FROM job_items WHERE status = 'missing' LIMIT 3;"
```

**Resultado esperado:**
```
        sku         | status  
--------------------+---------
JAQUETA-CINZA       | missing
BLUSA-BRANCA        | missing
```

---

#### ‚úÖ Crit√©rio 18: SKUs amb√≠guos marcam item como "ambiguous"

**Prepara√ß√£o - Criar assets similares:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db << EOF
INSERT INTO assets (tenant_id, sku_normalized, original_filename, file_uri, created_at, updated_at) VALUES 
  (1, 'SHORT-VERMELHO', 'short-verm1.png', 'tenant/1/assets/short1.png', NOW(), NOW()),
  (1, 'SHORT-VERMELHA', 'short-verm2.png', 'tenant/1/assets/short2.png', NOW(), NOW());
EOF
```

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT sku, status FROM job_items WHERE status = 'ambiguous';"
```

**Resultado esperado:**
```
      sku       | status    
----------------+-----------
SHORT-VERM      | ambiguous
```

---

#### ‚úÖ Crit√©rio 19: Job com pending items fica "needs_input"

**Valida√ß√£o:**
```bash
curl "http://localhost:8000/v1/jobs/1" -H "X-Tenant-ID: 1"
```

**Resultado esperado:**
```json
{
  "id": 1,
  "status": "needs_input",
  "items_count": 7,
  "items_resolved": 2,
  "items_pending": 5
}
```

---

#### ‚úÖ Crit√©rio 20: GET /pending-items retorna candidates

**Valida√ß√£o:**
```bash
curl "http://localhost:8000/v1/jobs/1/pending-items" \
  -H "X-Tenant-ID: 1"
```

**Resultado esperado:**
```json
{
  "items": [
    {
      "id": 5,
      "sku": "JAQUETA-CINZA",
      "quantity": 1,
      "size_label": "G",
      "status": "missing",
      "candidates": []
    },
    {
      "id": 2,
      "sku": "SHORT-VERM",
      "quantity": 3,
      "size_label": "M",
      "status": "ambiguous",
      "candidates": [
        {
          "asset_id": 10,
          "sku": "SHORT-VERMELHO",
          "file_uri": "tenant/1/assets/short1.png",
          "score": 0.65
        },
        {
          "asset_id": 11,
          "sku": "SHORT-VERMELHA",
          "file_uri": "tenant/1/assets/short2.png",
          "score": 0.63
        }
      ]
    }
  ]
}
```

---

#### ‚úÖ Crit√©rio 21: POST /resolve resolve items manualmente

**Valida√ß√£o:**
```bash
curl -X POST "http://localhost:8000/v1/jobs/1/resolve" \
  -H "X-Tenant-ID: 1" \
  -H "Content-Type: application/json" \
  -d '{
    "resolutions": [
      {"item_id": 2, "asset_id": 10},
      {"item_id": 5, "asset_id": 15}
    ]
  }'
```

**Resultado esperado:**
```json
{
  "status": "success",
  "resolved_count": 2,
  "job_status": "needs_input",
  "message": "Resolved 2 items. 3 items still need input."
}
```

**Status HTTP:** 200 OK

---

#### ‚úÖ Crit√©rio 22: Ap√≥s resolu√ß√£o manual, job volta para "queued"

**Valida√ß√£o (resolver todos os items):**
```bash
# Obter todos os pending items
PENDING=$(curl -s "http://localhost:8000/v1/jobs/1/pending-items" -H "X-Tenant-ID: 1")

# Resolver todos (ajustar IDs conforme necess√°rio)
curl -X POST "http://localhost:8000/v1/jobs/1/resolve" \
  -H "X-Tenant-ID: 1" \
  -H "Content-Type: application/json" \
  -d '{
    "resolutions": [
      {"item_id": 3, "asset_id": 1},
      {"item_id": 4, "asset_id": 1},
      {"item_id": 5, "asset_id": 1}
    ]
  }'
```

**Resultado esperado:**
```json
{
  "status": "success",
  "resolved_count": 3,
  "job_status": "queued",
  "message": "Items resolved. Job re-queued for processing."
}
```

**Verificar re-enfileiramento:**
```bash
docker-compose logs worker | grep "Starting job processing" | tail -1
```

---

## ‚úÖ FASE 4 - Dimensionamento, Layout e Renderiza√ß√£o (Valida√ß√£o)

### Resumo da Fase 4

**Entregue:**
- Feature 8: SizingService - Dimensionamento e valida√ß√µes
- Feature 9: PackingService - Motor de layout (sequence + optimize)
- Feature 10: RenderService - Gera√ß√£o de PDFs com ReportLab
- 2 novos endpoints (outputs e download)
- 3 novos servi√ßos (SizingService, PackingService, RenderService)
- Pipeline completo E2E: Upload ‚Üí Parse ‚Üí Resolve ‚Üí Size ‚Üí Pack ‚Üí Render
- Scripts de valida√ß√£o (test-sizing.py, test-packing.py, validate-phase-4.sh)

**Endpoints dispon√≠veis:**
- `GET /v1/jobs/{id}/outputs` - Lista bases geradas
- `GET /v1/jobs/{id}/outputs/{base}/download` - Download PDF

---

### Pr√©-requisitos para Fase 4

Antes de validar a Fase 4, certifique-se de que:

```bash
# 1. Instalar novas depend√™ncias no worker
docker-compose build worker
docker-compose up -d worker

# 2. Verificar que ReportLab foi instalado
docker-compose exec worker pip list | grep reportlab

# 3. Verificar worker reiniciou
docker-compose logs worker | tail -20
```

**Esperado:** Worker deve mostrar `celery@<hostname> ready.` e ter `reportlab==4.0.9`

---

### üì¶ Schema Updates e Corre√ß√µes

#### Sizing Profiles - Auto-Matching por SKU Prefix

A tabela `sizing_profiles` foi atualizada com novos campos para suportar auto-matching por SKU prefix:

**Mudan√ßas no Schema:**
```sql
ALTER TABLE sizing_profiles 
ADD COLUMN IF NOT EXISTS sku_prefix VARCHAR(20) DEFAULT NULL,
ADD COLUMN IF NOT EXISTS is_default BOOLEAN DEFAULT FALSE;
```

**Como aplicar manualmente:**
```bash
# Adicionar colunas
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "
ALTER TABLE sizing_profiles 
ADD COLUMN IF NOT EXISTS sku_prefix VARCHAR(20) DEFAULT NULL,
ADD COLUMN IF NOT EXISTS is_default BOOLEAN DEFAULT FALSE;
"

# Criar √≠ndices para performance
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "
CREATE UNIQUE INDEX IF NOT EXISTS idx_sizing_profile_prefix 
ON sizing_profiles(tenant_id, sku_prefix) 
WHERE sku_prefix IS NOT NULL;

CREATE INDEX IF NOT EXISTS idx_sizing_profile_default 
ON sizing_profiles(tenant_id, is_default) 
WHERE is_default = TRUE;
"

# Reiniciar API e Worker para carregar modelo atualizado
docker-compose restart api worker
```

**Verificar mudan√ßas:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "
SELECT column_name, data_type, is_nullable, column_default
FROM information_schema.columns 
WHERE table_name = 'sizing_profiles' 
AND column_name IN ('sku_prefix', 'is_default');
"
```

**Resultado esperado:**
```
 column_name  |     data_type      | is_nullable | column_default 
--------------+--------------------+-------------+----------------
 sku_prefix   | character varying  | YES         | NULL
 is_default   | boolean            | NO          | false
```

#### Storage Configs - Corre√ß√£o de Nomenclatura dos Campos

Os campos da API de `storage_configs` foram corrigidos para corresponder ao modelo do banco de dados:

**Nomes Corretos (API ‚Üî Database):**
- `provider` (antes era `storage_type`) ‚Üí Tipo do storage: `"local"`, `"s3"`, `"dropbox"`
- `base_path` (antes era `storage_path`) ‚Üí Caminho base do armazenamento
- `credentials_encrypted` (opcional) ‚Üí Credenciais criptografadas em JSON

**Exemplo de cria√ß√£o:**
```bash
curl -X POST "http://localhost:8000/v1/storage-configs" \
  -H "X-Tenant-ID: 2" \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "local",
    "base_path": "/tmp/printer-queue-assets/tenant-2"
  }'
```

**Nota:** Os campos `tenant_id`, `machine_id`, `sizing_profile_id` foram removidos do body das requisi√ß√µes de cria√ß√£o e agora usam exclusivamente o header `X-Tenant-ID` para seguran√ßa e consist√™ncia.

---

### Feature 8: Dimensionamento e Valida√ß√µes

#### üìê Auto-Matching de Sizing Profiles por SKU Prefix

Os **Sizing Profiles** agora suportam **matching autom√°tico** baseado em prefixos de SKU:

**Campos novos:**
- `sku_prefix`: Prefixo do SKU para matching autom√°tico (ex: `"inf-"`, `"plus-"`, `"bl-"`)
- `is_default`: Define se este profile ser√° usado quando nenhum prefix combinar

**Como funciona:**
1. Quando um job √© processado, cada item tem um SKU (ex: `"inf-1-6-unicorn-4.png"`)
2. O sistema procura um sizing profile cujo `sku_prefix` combina com o in√≠cio do SKU
3. Se encontrar, usa aquele profile para dimensionar o item
4. Se n√£o encontrar nenhum match, usa o profile marcado como `is_default=true`

**Exemplos de matching:**
```
SKU: "inf-1-6-unicorn-4.png"      ‚Üí Profile "Infantil" (prefix: "inf-", 60mm)
SKU: "plus-4-1-sakura-g3.png"     ‚Üí Profile "Plus Size" (prefix: "plus-", 160mm)
SKU: "u-7-3-queen-gg.png"         ‚Üí Profile "UNISSEX" (prefix: "u-", 100mm)
SKU: "bl-5-2-blackcat-m.png"      ‚Üí Profile "Baby Look" (prefix: "bl-", 70mm)
SKU: "unknown-sku-123.png"        ‚Üí Profile "UNISSEX" (is_default: true, 100mm)
```

**Vantagens:**
- ‚úÖ Cada item pode ter tamanho diferente automaticamente
- ‚úÖ Usu√°rio define seus pr√≥prios padr√µes de nomenclatura
- ‚úÖ N√£o precisa especificar `sizing_profile_id` no job (opcional)
- ‚úÖ Matching exato e r√°pido por prefixo

**Nota:** O par√¢metro `sizing_profile_id` no endpoint de jobs ainda √© suportado para compatibilidade, mas n√£o √© mais necess√°rio com o auto-matching.

---

#### ‚úÖ Crit√©rio 1: Sizing profiles s√£o aplicados corretamente

**Valida√ß√£o com script de teste:**
```bash
# Executar test unit√°rio de sizing
python3 scripts/test-sizing.py
```

**Resultado esperado:**
```
============================================================
SIZING SERVICE TEST
============================================================

Test 1: Normal sizing (800x1200px, 300 DPI, target 100mm)
------------------------------------------------------------
Valid: True
Final dimensions: 100.0mm x 150.0mm
Scale applied: 1.00
Warnings: []

Test 2: Low DPI (800x1200px, 150 DPI)
------------------------------------------------------------
Valid: False
Error: DPI too low (150). Minimum required: 300

Test 3: Image too wide (needs scaling)
------------------------------------------------------------
Valid: True
Final dimensions: 560.0mm x 840.0mm
Scale applied: 0.86 (86%)
Warnings: ['Item 1 (SKU: TEST001): scaled to 86% to fit width...']
```

---

#### ‚úÖ Crit√©rio 2: Items com dimens√µes finais ap√≥s sizing

**Prepara√ß√£o - Criar job que resolve completamente:**
```bash
# 1. Garantir que existem assets no banco
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT COUNT(*) FROM assets WHERE tenant_id = 1;"

# Se n√£o houver assets, reindexar
curl -X POST http://localhost:8000/v1/assets/reindex \
  -H "X-Tenant-ID: 1" \
  -H "Content-Type: application/json" \
  -d '{}'

# 2. Upload picklist
curl -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 1" \
  -F "file=@test_picklist.pdf" \
  -F "mode=sequence" \
  -F "machine_id=1"
  # sizing_profile_id omitido - usa auto-matching por SKU prefix
```

**Aguardar processamento completo:**
```bash
# Aguardar 30 segundos para job completar todo o pipeline
sleep 30
```

**Valida√ß√£o - Items t√™m dimens√µes finais:**
```bash
# Pegar √∫ltimo job criado
JOB_ID=$(docker-compose exec -T postgres psql -U printer_queue -d printer_queue_db \
  -t -c "SELECT id FROM jobs ORDER BY id DESC LIMIT 1;" | tr -d ' ')

echo "Validating job: $JOB_ID"

# Verificar items com dimens√µes
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, sku, status, final_width_mm, final_height_mm FROM job_items WHERE job_id = $JOB_ID LIMIT 5;"
```

**Resultado esperado:**
```
 id |    sku     | status   | final_width_mm | final_height_mm 
----+------------+----------+----------------+-----------------
  1 | CAM001     | packed   |          100.0 |           150.0
  2 | CAM002     | packed   |          100.0 |           150.0
  3 | CAM003     | packed   |          100.0 |           150.0
```

Todos os items devem ter `final_width_mm` e `final_height_mm` preenchidos.

---

#### ‚úÖ Crit√©rio 3: Valida√ß√£o de DPI funciona

**Valida√ß√£o - Ver manifest com sizing info:**
```bash
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .sizing'
```

**Resultado esperado:**
```json
{
  "total_items": 7,
  "valid_items": 7,
  "invalid_items": 0,
  "scaled_items": 2,
  "warnings": [
    "Item 3 (SKU: CAM003): scaled to 95% to fit width (120mm -> 114mm)"
  ]
}
```

---

#### ‚úÖ Crit√©rio 4: Items inv√°lidos bloqueiam o job

**Prepara√ß√£o - Criar asset com DPI baixo:**
```bash
# Inserir asset com metadata de DPI baixo
docker-compose exec postgres psql -U printer_queue -d printer_queue_db << EOF
INSERT INTO assets (tenant_id, sku_normalized, original_filename, file_uri, metadata_json, created_at, updated_at) 
VALUES (
  1, 
  'LOW-DPI-TEST', 
  'low-dpi.png', 
  'tenant/1/assets/low-dpi.png',
  '{"width_px": 800, "height_px": 1200, "dpi": 150, "format": "PNG"}',
  NOW(), 
  NOW()
);
EOF
```

**Nota:** Na valida√ß√£o real, o sistema detectaria DPI baixo e marcaria o job como `failed`. Para este teste, garantir que assets tenham DPI adequado (‚â•300).

---

### Feature 9: Packing/Layout

#### ‚úÖ Crit√©rio 5: Algoritmo sequence mant√©m ordem

**Valida√ß√£o com script de teste:**
```bash
# Executar test unit√°rio de packing
python3 scripts/test-packing.py
```

**Resultado esperado:**
```
============================================================
PACKING SERVICE TEST
============================================================

TEST 1: SEQUENCE MODE (maintain order)
============================================================

Results:
  Total bases: 2
  Total length: 2450mm
  Avg utilization: 78.3%

  Base 1
  --------------------------------------------------
  Dimensions: 600mm x 1850mm
  Items: 7
  Utilization: 82.5%
```

---

#### ‚úÖ Crit√©rio 6: Modo optimize reduz desperd√≠cio

**Valida√ß√£o - Compara√ß√£o no script:**
```bash
# O script test-packing.py j√° compara sequence vs optimize
# Verificar output da se√ß√£o COMPARISON
```

**Resultado esperado:**
```
COMPARISON (10 items)
========================================
Mode         Bases     Length     Util
----------------------------------------
Sequence         2       2450    78.3%
Optimize         2       2280    85.7%

----------------------------------------
Optimize saved: 170mm (6.9%)
```

Optimize deve ter utiliza√ß√£o maior e/ou comprimento menor.

---

#### ‚úÖ Crit√©rio 7: Items t√™m posi√ß√µes (x, y, base_index)

**Valida√ß√£o:**
```bash
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, sku, base_index, x_mm, y_mm FROM job_items WHERE job_id = $JOB_ID AND base_index IS NOT NULL LIMIT 5;"
```

**Resultado esperado:**
```
 id |   sku   | base_index | x_mm | y_mm 
----+---------+------------+------+------
  1 | CAM001  |          1 | 20.0 | 20.0
  2 | CAM002  |          1 | 130.0| 20.0
  3 | CAM003  |          1 | 240.0| 20.0
  4 | CAM004  |          2 | 20.0 | 20.0
```

Todos items devem ter `base_index`, `x_mm`, e `y_mm` preenchidos.

---

#### ‚úÖ Crit√©rio 8: Manifest inclui layout completo

**Valida√ß√£o:**
```bash
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .packing'
```

**Resultado esperado:**
```json
{
  "mode": "sequence",
  "total_bases": 2,
  "total_length_mm": 2450.0,
  "avg_utilization": 78.3,
  "bases": [
    {
      "index": 1,
      "width_mm": 600.0,
      "length_mm": 1850.0,
      "utilization": 82.5,
      "items_count": 7,
      "placements": [
        {
          "item_id": 1,
          "sku": "CAM001",
          "x_mm": 20.0,
          "y_mm": 20.0,
          "width_mm": 100.0,
          "height_mm": 150.0,
          "rotated": false
        }
      ]
    }
  ]
}
```

---

### Feature 10: Renderiza√ß√£o de PDFs

#### ‚úÖ Crit√©rio 9: Job status muda para "completed"

**Valida√ß√£o:**
```bash
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '{id, status, completed_at}'
```

**Resultado esperado:**
```json
{
  "id": 11,
  "status": "completed",
  "completed_at": "2026-01-16T20:30:00Z"
}
```

---

#### ‚úÖ Crit√©rio 10: PDFs s√£o gerados e salvos no storage

**Valida√ß√£o:**
```bash
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .outputs'
```

**Resultado esperado:**
```json
{
  "pdfs": [
    "tenant/1/outputs/11/base_1.pdf",
    "tenant/1/outputs/11/base_2.pdf"
  ],
  "previews": []
}
```

**Verificar no storage (local):**
```bash
ls -lh /tmp/printer-queue-assets/tenant-1/outputs/*/
```

**Resultado esperado:**
```
-rw-r--r-- 1 user user 2.5M Jan 16 20:30 base_1.pdf
-rw-r--r-- 1 user user 1.8M Jan 16 20:30 base_2.pdf
```

---

#### ‚úÖ Crit√©rio 11: Endpoint outputs lista bases

**Valida√ß√£o:**
```bash
curl "http://localhost:8000/v1/jobs/$JOB_ID/outputs" \
  -H "X-Tenant-ID: 1"
```

**Resultado esperado:**
```json
{
  "job_id": 11,
  "status": "completed",
  "total_bases": 2,
  "bases": [
    {
      "index": 1,
      "pdf_uri": "tenant/1/outputs/11/base_1.pdf",
      "preview_uri": null,
      "width_mm": 600.0,
      "length_mm": 1850.0,
      "items_count": 7,
      "utilization": 82.5
    },
    {
      "index": 2,
      "pdf_uri": "tenant/1/outputs/11/base_2.pdf",
      "preview_uri": null,
      "width_mm": 600.0,
      "length_mm": 600.0,
      "items_count": 3,
      "utilization": 75.2
    }
  ]
}
```

---

#### ‚úÖ Crit√©rio 12: Download de PDF funciona

**Valida√ß√£o:**
```bash
# Download base 1
curl "http://localhost:8000/v1/jobs/$JOB_ID/outputs/1/download" \
  -H "X-Tenant-ID: 1" \
  --output base_1.pdf

# Verificar arquivo
file base_1.pdf
ls -lh base_1.pdf
```

**Resultado esperado:**
```
base_1.pdf: PDF document, version 1.4
-rw-r--r-- 1 user user 2.5M Jan 16 20:35 base_1.pdf
```

---

#### ‚úÖ Crit√©rio 13: PDF abre corretamente

**Valida√ß√£o manual:**
```bash
# Abrir PDF em visualizador
# macOS
open base_1.pdf

# Linux
xdg-open base_1.pdf

# Windows
start base_1.pdf
```

**Verifica√ß√µes visuais:**
- [ ] PDF abre sem erros
- [ ] Dimens√µes corretas (verificar propriedades)
- [ ] Imagens aparecem nas posi√ß√µes corretas
- [ ] Sem overlapping de imagens
- [ ] Qualidade das imagens est√° boa
- [ ] Transpar√™ncia preservada (se PNG)

---

#### ‚úÖ Crit√©rio 14: Manifest inclui processing time

**Valida√ß√£o:**
```bash
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | {processing_time_seconds, completed_at}'
```

**Resultado esperado:**
```json
{
  "processing_time_seconds": 28.5,
  "completed_at": "2026-01-16T20:30:00Z"
}
```

---

### Teste End-to-End Completo da Fase 4

**Script automatizado:**
```bash
./scripts/validate-phase-4.sh
```

**Passo a passo manual:**

```bash
# 1. Limpar ambiente anterior (opcional)
docker-compose down -v
docker-compose up -d --build
sleep 20

# 2. Setup banco
docker-compose run --rm api alembic upgrade head
docker-compose run --rm api python -m app.db.seed

# 3. Criar assets de teste (com metadata correto)
docker-compose exec postgres psql -U printer_queue -d printer_queue_db << 'EOF'
INSERT INTO assets (tenant_id, sku_normalized, original_filename, file_uri, metadata_json, created_at, updated_at) 
VALUES 
  (1, 'CAM001', 'cam001.png', 'tenant/1/assets/cam001.png', 
   '{"width_px": 1000, "height_px": 1500, "dpi": 300, "format": "PNG"}', NOW(), NOW()),
  (1, 'CAM002', 'cam002.png', 'tenant/1/assets/cam002.png', 
   '{"width_px": 1000, "height_px": 1500, "dpi": 300, "format": "PNG"}', NOW(), NOW()),
  (1, 'CAM003', 'cam003.png', 'tenant/1/assets/cam003.png', 
   '{"width_px": 1200, "height_px": 1800, "dpi": 300, "format": "PNG"}', NOW(), NOW()),
  (1, 'CAM004', 'cam004.png', 'tenant/1/assets/cam004.png', 
   '{"width_px": 800, "height_px": 1200, "dpi": 300, "format": "PNG"}', NOW(), NOW()),
  (1, 'CAM005', 'cam005.png', 'tenant/1/assets/cam005.png', 
   '{"width_px": 1000, "height_px": 1500, "dpi": 300, "format": "PNG"}', NOW(), NOW());
EOF

# 4. Criar picklist de teste
python3 scripts/create-test-picklist.py -o test_picklist.pdf

# 5. Upload picklist com modo optimize
JOB_RESPONSE=$(curl -s -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 1" \
  -F "file=@test_picklist.pdf" \
  -F "mode=optimize" \
  -F "machine_id=1")
  # sizing_profile_id omitido - usa auto-matching por SKU prefix

JOB_ID=$(echo "$JOB_RESPONSE" | jq -r '.id')
echo "‚úì Job created: $JOB_ID"

# 6. Aguardar processamento completo
echo "Waiting for job to complete..."
for i in {1..60}; do
  STATUS=$(curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq -r '.status')
  echo -n "."
  
  if [ "$STATUS" = "completed" ]; then
    echo ""
    echo "‚úì Job completed"
    break
  elif [ "$STATUS" = "failed" ]; then
    echo ""
    echo "‚úó Job failed"
    curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .error'
    exit 1
  fi
  
  sleep 1
done

# 7. Verificar manifest completo
echo ""
echo "=== SIZING ==="
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .sizing'

echo ""
echo "=== PACKING ==="
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .packing | {mode, total_bases, total_length_mm, avg_utilization}'

echo ""
echo "=== OUTPUTS ==="
curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .outputs'

# 8. Verificar items com dimens√µes
echo ""
echo "=== JOB ITEMS ==="
docker-compose exec -T postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, sku, status, final_width_mm, final_height_mm, base_index, x_mm, y_mm FROM job_items WHERE job_id = $JOB_ID LIMIT 5;"

# 9. Listar outputs
echo ""
echo "=== BASES ==="
curl -s "http://localhost:8000/v1/jobs/$JOB_ID/outputs" -H "X-Tenant-ID: 1" | jq '.bases[] | {index, width_mm, length_mm, items_count, utilization}'

# 10. Download PDFs
echo ""
echo "Downloading PDFs..."
BASES=$(curl -s "http://localhost:8000/v1/jobs/$JOB_ID/outputs" -H "X-Tenant-ID: 1" | jq -r '.total_bases')

for base in $(seq 1 $BASES); do
  curl -s "http://localhost:8000/v1/jobs/$JOB_ID/outputs/$base/download" \
    -H "X-Tenant-ID: 1" \
    --output "job_${JOB_ID}_base_${base}.pdf"
  
  if [ -f "job_${JOB_ID}_base_${base}.pdf" ]; then
    SIZE=$(ls -lh "job_${JOB_ID}_base_${base}.pdf" | awk '{print $5}')
    echo "‚úì Downloaded base $base: $SIZE"
  else
    echo "‚úó Failed to download base $base"
  fi
done

# 11. Verificar PDFs
echo ""
echo "=== PDF VALIDATION ==="
for base in $(seq 1 $BASES); do
  FILE="job_${JOB_ID}_base_${base}.pdf"
  if [ -f "$FILE" ]; then
    file "$FILE"
  fi
done

echo ""
echo "============================================"
echo "‚úì PHASE 4 VALIDATION COMPLETE"
echo "============================================"
echo ""
echo "Manual checks:"
echo "  1. Open PDFs in viewer (open job_*.pdf)"
echo "  2. Verify image positions are correct"
echo "  3. Verify dimensions match manifest"
echo "  4. Check image quality"
```

---

## üéØ Teste Completo End-to-End

### Script de Valida√ß√£o Automatizada

```bash
# Valida√ß√£o Fase 1 + Fase 2
chmod +x scripts/validate-phase-2.sh
./scripts/validate-phase-2.sh

# Valida√ß√£o Fase 3
chmod +x scripts/validate-phase-3.sh
./scripts/validate-phase-3.sh

# Valida√ß√£o Fase 4
chmod +x scripts/validate-phase-4.sh
./scripts/validate-phase-4.sh
```

### Valida√ß√£o Manual Completa

Execute todos os comandos em sequ√™ncia:

```bash
# 1. Limpar ambiente
docker-compose down -v

# 2. Criar .env (copie do exemplo acima)

# 3. Build e subir stack
docker-compose up -d --build

# 4. Aguardar servi√ßos
sleep 20

# 5. Executar migrations
docker-compose run --rm api alembic upgrade head

# 6. Executar seeds
docker-compose run --rm api python -m app.db.seed

# 7. Criar test assets
mkdir -p /tmp/printer-queue-assets/tenant-1
# (executar create-test-assets.sh ou criar manualmente)

# === FASE 1 ===

# 8. Testar health
curl http://localhost:8000/health

# 9. Verificar extens√£o pg_trgm
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT extname FROM pg_extension WHERE extname = 'pg_trgm';"

# 10. Verificar tabelas (deve ter 8)
docker-compose exec postgres psql -U printer_queue -d printer_queue_db -c "\dt"

# 11. Verificar seeds
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT name FROM tenants;"

# 12. Verificar worker
docker-compose logs worker | grep "ready"

# === FASE 2 ===

# 13. Rebuild worker com Docling
docker-compose build worker
docker-compose up -d worker

# 14. Testar storage
curl -X POST http://localhost:8000/v1/storage/test -H "X-Tenant-ID: 1"

# 15. Reindexar assets
TASK_ID=$(curl -X POST http://localhost:8000/v1/assets/reindex \
  -H "X-Tenant-ID: 1" -H "Content-Type: application/json" -d '{}' \
  | jq -r '.task_id')

echo "Task ID: $TASK_ID"

# 16. Aguardar reindexa√ß√£o
sleep 10

# 17. Verificar status
curl "http://localhost:8000/v1/assets/reindex/$TASK_ID" -H "X-Tenant-ID: 1"

# 18. Verificar assets no banco
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT COUNT(*) FROM assets WHERE tenant_id = 1;"

# 19. Busca exata
curl "http://localhost:8000/v1/assets/search?sku=cam001" -H "X-Tenant-ID: 1"

# 20. Busca fuzzy
curl "http://localhost:8000/v1/assets/search?sku=cam&threshold=0.3" \
  -H "X-Tenant-ID: 1"

# 21. Listar assets
curl "http://localhost:8000/v1/assets" -H "X-Tenant-ID: 1"

# === FASE 3 ===

# 22. Rebuild worker com Docling e ReportLab
docker-compose build worker
docker-compose up -d worker

# 23. Criar test picklist
python3 scripts/create-test-picklist.py -o test_picklist.pdf

# 23. Upload picklist
JOB_RESPONSE=$(curl -s -X POST http://localhost:8000/v1/jobs \
  -H "X-Tenant-ID: 1" \
  -F "file=@test_picklist.pdf" \
  -F "mode=sequence" \
  -F "machine_id=1")

JOB_ID=$(echo "$JOB_RESPONSE" | jq -r '.id')
echo "Job created: $JOB_ID"

# 24. Aguardar processamento
sleep 15

# 25. Verificar status do job
curl "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1"

# 26. Verificar job items criados
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT COUNT(*) FROM job_items WHERE job_id = $JOB_ID;"

# 27. Listar jobs
curl "http://localhost:8000/v1/jobs?page=1&size=10" -H "X-Tenant-ID: 1"

# 28. Se job precisa input, ver pending items
JOB_STATUS=$(curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq -r '.status')

if [ "$JOB_STATUS" = "needs_input" ]; then
  echo "Job needs input. Checking pending items..."
  curl "http://localhost:8000/v1/jobs/$JOB_ID/pending-items" -H "X-Tenant-ID: 1"
fi

# === FASE 4 ===

# 29. Se job completou, verificar sizing
if [ "$JOB_STATUS" = "completed" ]; then
  echo "Job completed! Checking Phase 4 outputs..."
  
  # Verificar sizing
  echo "=== SIZING ==="
  curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .sizing'
  
  # Verificar packing
  echo ""
  echo "=== PACKING ==="
  curl -s "http://localhost:8000/v1/jobs/$JOB_ID" -H "X-Tenant-ID: 1" | jq '.manifest_json | fromjson | .packing | {mode, total_bases, avg_utilization}'
  
  # Verificar outputs
  echo ""
  echo "=== OUTPUTS ==="
  curl "http://localhost:8000/v1/jobs/$JOB_ID/outputs" -H "X-Tenant-ID: 1"
  
  # Download primeiro PDF
  echo ""
  echo "Downloading base 1..."
  curl "http://localhost:8000/v1/jobs/$JOB_ID/outputs/1/download" \
    -H "X-Tenant-ID: 1" \
    --output "base_1.pdf"
  
  if [ -f "base_1.pdf" ]; then
    ls -lh base_1.pdf
    file base_1.pdf
    echo "‚úì PDF downloaded successfully!"
  fi
fi

echo ""
echo "‚úì Valida√ß√£o completa Fase 1 + Fase 2 + Fase 3 + Fase 4!"
```

---

---

## üìä Checklist de Valida√ß√£o

### Fase 1 - Funda√ß√£o
- [x] Docker Compose sobe sem erros (4 servi√ßos)
- [x] Health endpoint retorna 200
- [x] Worker est√° ready (logs)
- [x] Extens√£o pg_trgm habilitada
- [x] 8 tabelas criadas
- [x] Seeds executados (1 tenant, 1 machine, 4 profiles, 1 storage config)
- [x] √çndice trigram existe
- [x] Endpoint /v1/tenants funciona

### Fase 2 - Storage e Indexa√ß√£o
- [x] Storage test retorna OK
- [x] Reindexa√ß√£o dispara sem erros
- [x] Worker processa reindexa√ß√£o
- [x] Assets salvos no banco (5+)
- [x] SKU extra√≠do corretamente
- [x] Metadados extra√≠dos (width, height, format)
- [x] Busca exata funciona (score 1.0)
- [x] Busca fuzzy retorna matches similares
- [x] Listagem com pagina√ß√£o funciona
- [x] Detalhes de asset com metadata parsed

### Fase 3 - Ingest√£o de Picklist e Pipeline
- [x] Upload de PDF cria job com status "queued"
- [x] PDF salvo no storage correto
- [x] Worker processa PDF e extrai items
- [x] Job items criados no banco
- [x] Raw extraction salvo em manifest_json
- [x] SKUs normalizados (uppercase, trim)
- [x] Match exato resolve automaticamente
- [x] Match fuzzy funciona (threshold 0.7)
- [x] Items missing marcados corretamente
- [x] Items ambiguous marcados corretamente
- [x] Job fica "needs_input" quando necess√°rio
- [x] Endpoint pending-items retorna candidates
- [x] Resolu√ß√£o manual funciona
- [x] Job re-enfileira ap√≥s resolu√ß√£o completa
- [x] Listagem de jobs funciona
- [x] Valida√ß√µes de upload funcionam (size, storage)

### Fase 4 - Dimensionamento, Layout e Renderiza√ß√£o
- [x] ReportLab instalado no worker
- [x] Sizing profiles aplicados corretamente
- [x] Items t√™m final_width_mm e final_height_mm
- [x] DPI validado contra m√≠nimo da m√°quina
- [x] Formato validado (PNG, JPEG aceitos)
- [x] Items que excedem largura s√£o escalados
- [x] Warnings de escala registrados
- [x] Items inv√°lidos marcados corretamente
- [x] Modo sequence mant√©m ordem do picklist
- [x] Modo optimize reduz desperd√≠cio
- [x] Quebra autom√°tica em m√∫ltiplas bases funciona
- [x] Items t√™m base_index, x_mm, y_mm
- [x] Manifest inclui layout completo (packing)
- [x] Utiliza√ß√£o de cada base √© calculada
- [x] PDFs gerados com dimens√µes corretas
- [x] PDFs salvos no storage
- [x] URIs dos PDFs no manifest
- [x] Job status muda para "completed"
- [x] Endpoint outputs lista bases
- [x] Download de PDF funciona
- [x] PDFs abrem corretamente
- [x] Processing time registrado

---

## üêõ Troubleshooting

### Erro: Port already in use

```bash
# Verificar o que est√° usando a porta
lsof -i :8000
lsof -i :5432

# Parar containers
docker-compose down
```

### Erro: Connection refused na API

```bash
# Ver logs da API
docker-compose logs api

# Restart
docker-compose restart api

# Aguardar
sleep 5
curl http://localhost:8000/health
```

### Erro: Worker n√£o processa tasks

```bash
# Ver logs do worker
docker-compose logs worker

# Verificar conex√£o Redis
docker-compose logs redis

# Restart worker
docker-compose restart worker
```

### Erro: Storage not configured

```bash
# Re-executar seeds
docker-compose run --rm api python -m app.db.seed

# Ou inserir manualmente
docker-compose exec postgres psql -U printer_queue -d printer_queue_db
# INSERT INTO tenant_storage_configs ...
```

### Erro: No files found na reindexa√ß√£o

```bash
# Verificar se assets existem
ls -lh /tmp/printer-queue-assets/tenant-1/

# Criar test assets
./scripts/create-test-assets.sh

# Verificar permiss√µes
chmod -R 755 /tmp/printer-queue-assets/
```

### Erro: Migrations falham

```bash
# Verificar Postgres
docker-compose logs postgres

# Limpar e recriar
docker-compose down -v
docker-compose up -d postgres
sleep 10
docker-compose run --rm api alembic upgrade head
```

### Erro: Import errors no Worker

```bash
# Rebuild containers
docker-compose build worker
docker-compose restart worker

# Ver logs detalhados
docker-compose logs -f worker
```

### Erro: Docling parsing falha (Fase 3)

```bash
# Verificar se Docling foi instalado
docker-compose exec worker pip list | grep docling

# Rebuild com depend√™ncias
docker-compose build worker
docker-compose up -d worker

# Verificar primeira execu√ß√£o (baixa models)
docker-compose logs -f worker
```

### Erro: Job fica em "processing" indefinidamente

```bash
# Ver logs do worker
docker-compose logs worker | tail -50

# Verificar se worker travou
docker-compose restart worker

# Verificar job no banco
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT id, status, updated_at FROM jobs ORDER BY id DESC LIMIT 5;"
```

### Erro: SKU resolution n√£o encontra matches

```bash
# Verificar se existem assets
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT COUNT(*) FROM assets WHERE tenant_id = 1;"

# Verificar normaliza√ß√£o do SKU
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT sku, sku_normalized FROM job_items WHERE job_id = 1 LIMIT 3;"

# Testar similarity manualmente
docker-compose exec postgres psql -U printer_queue -d printer_queue_db \
  -c "SELECT sku_normalized, similarity(sku_normalized, 'CAMISA-AZUL') as score FROM assets WHERE tenant_id = 1 ORDER BY score DESC LIMIT 5;"
```

---

## üßπ Limpeza

### Limpar Completamente

```bash
# Parar e remover tudo
docker-compose down -v

# Remover imagens
docker-compose rm -f

# Limpar sistema Docker
docker system prune -f

# Remover assets de teste
rm -rf /tmp/printer-queue-assets/
```

### Limpar Apenas Dados

```bash
# Remover volumes (perde dados do banco)
docker-compose down -v

# Manter containers, apenas restart
docker-compose restart
```

---

## üöÄ Teste R√°pido - Novo Tenant via REST API

### Setup Completo de Tenant 2 com APIs

Script bash para criar e testar um tenant completo usando apenas REST APIs:

```bash
#!/bin/bash

# 1. Criar Tenant
TENANT_RESPONSE=$(curl -s -X POST "http://localhost:8000/v1/tenants" \
  -H "Content-Type: application/json" \
  -d '{"name": "Tenant Test 2"}')

TENANT_ID=$(echo "$TENANT_RESPONSE" | jq -r '.id')
echo "‚úì Tenant criado: ID $TENANT_ID"

# 2. Criar Storage Config (tenant_id vem do header)
curl -s -X POST "http://localhost:8000/v1/storage-configs" \
  -H "X-Tenant-ID: $TENANT_ID" \
  -H "Content-Type: application/json" \
  -d "{
    \"provider\": \"local\",
    \"base_path\": \"/tmp/printer-queue-assets/tenant-$TENANT_ID\"
  }" > /dev/null
echo "‚úì Storage config criado"

# 3. Criar diret√≥rio
mkdir -p "/tmp/printer-queue-assets/tenant-$TENANT_ID"/{assets,picklists,outputs}
echo "‚úì Diret√≥rio criado"

# 4. Criar Machine (tenant_id vem do header)
MACHINE_RESPONSE=$(curl -s -X POST "http://localhost:8000/v1/machines" \
  -H "X-Tenant-ID: $TENANT_ID" \
  -H "Content-Type: application/json" \
  -d "{
    \"name\": \"DTF Printer Test\",
    \"max_width_mm\": 600,
    \"max_length_mm\": 2500,
    \"min_dpi\": 300
  }")

MACHINE_ID=$(echo "$MACHINE_RESPONSE" | jq -r '.id')
echo "‚úì Machine criada: ID $MACHINE_ID"

# 5. Criar Sizing Profiles com SKU prefix matching (tenant_id vem do header)
# Infantil (60mm) - SKUs que come√ßam com "inf-"
curl -s -X POST "http://localhost:8000/v1/sizing-profiles" \
  -H "X-Tenant-ID: $TENANT_ID" \
  -H "Content-Type: application/json" \
  -d '{
    "size_label": "Infantil",
    "target_width_mm": 60.0,
    "sku_prefix": "inf-",
    "is_default": false
  }' > /dev/null
echo "‚úì Sizing profile: Infantil (60mm, prefix: inf-)"

# Baby Look (70mm) - SKUs que come√ßam com "bl-"
curl -s -X POST "http://localhost:8000/v1/sizing-profiles" \
  -H "X-Tenant-ID: $TENANT_ID" \
  -H "Content-Type: application/json" \
  -d '{
    "size_label": "Baby Look",
    "target_width_mm": 70.0,
    "sku_prefix": "bl-",
    "is_default": false
  }' > /dev/null
echo "‚úì Sizing profile: Baby Look (70mm, prefix: bl-)"

# Unissex (100mm) - SKUs que come√ßam com "u-" - DEFAULT
curl -s -X POST "http://localhost:8000/v1/sizing-profiles" \
  -H "X-Tenant-ID: $TENANT_ID" \
  -H "Content-Type: application/json" \
  -d '{
    "size_label": "UNISSEX",
    "target_width_mm": 100.0,
    "sku_prefix": "u-",
    "is_default": true
  }' > /dev/null
echo "‚úì Sizing profile: UNISSEX (100mm, prefix: u-, DEFAULT)"

# Masculino (110mm) - SKUs que come√ßam com "m-"
curl -s -X POST "http://localhost:8000/v1/sizing-profiles" \
  -H "X-Tenant-ID: $TENANT_ID" \
  -H "Content-Type: application/json" \
  -d '{
    "size_label": "Masculino",
    "target_width_mm": 110.0,
    "sku_prefix": "m-",
    "is_default": false
  }' > /dev/null
echo "‚úì Sizing profile: Masculino (110mm, prefix: m-)"

# Plus Size (160mm) - SKUs que come√ßam com "plus-"
curl -s -X POST "http://localhost:8000/v1/sizing-profiles" \
  -H "X-Tenant-ID: $TENANT_ID" \
  -H "Content-Type: application/json" \
  -d '{
    "size_label": "Plus Size",
    "target_width_mm": 160.0,
    "sku_prefix": "plus-",
    "is_default": false
  }' > /dev/null
echo "‚úì Sizing profile: Plus Size (160mm, prefix: plus-)"

echo ""
echo "=========================================="
echo "‚úÖ TENANT $TENANT_ID CONFIGURADO"
echo "Machine ID: $MACHINE_ID"
echo "Pronto para criar assets e processar jobs!"
echo "=========================================="
```

### Exemplo Completo: Do Tenant ao PDF

```bash
# Ver documenta√ß√£o completa dos endpoints administrativos
cat ADMIN_API_GUIDE.md

# Ou acessar documenta√ß√£o interativa
open http://localhost:8000/docs
```

---

## üìö Refer√™ncias e Documenta√ß√£o

### Fase 3
- **[PHASE_3_COMPLETE.md](./PHASE_3_COMPLETE.md)** - Documenta√ß√£o completa da implementa√ß√£o
- **[QUICK_START_PHASE_3.md](./QUICK_START_PHASE_3.md)** - Guia r√°pido de in√≠cio
- **[scripts/validate-phase-3.sh](./scripts/validate-phase-3.sh)** - Script de valida√ß√£o automatizada
- **[scripts/create-test-picklist.py](./scripts/create-test-picklist.py)** - Gerador de PDFs de teste

### Fase 4
- **[PHASE_4_COMPLETE.md](./PHASE_4_COMPLETE.md)** - Documenta√ß√£o completa da implementa√ß√£o
- **[PHASE_4_PROMPT.md](./PHASE_4_PROMPT.md)** - Especifica√ß√£o t√©cnica original
- **[scripts/test-sizing.py](./scripts/test-sizing.py)** - Teste unit√°rio de dimensionamento
- **[scripts/test-packing.py](./scripts/test-packing.py)** - Teste unit√°rio de packing
- **[scripts/validate-phase-4.sh](./scripts/validate-phase-4.sh)** - Script de valida√ß√£o automatizada

### Endpoints Administrativos
- **[ADMIN_API_GUIDE.md](./ADMIN_API_GUIDE.md)** - Guia completo de APIs administrativas
- Endpoints para Tenants, Machines, Sizing Profiles e Storage Configs
- Exemplos de uso e scripts bash prontos

## Pr√≥ximos Passos

Ap√≥s valida√ß√£o completa das Fases 1, 2, 3 e 4:
- **MVP est√° 90% completo!** ‚úÖ
- **Fase 5:** Observabilidade (logs, metrics, tracing)
- **Fase 6:** Rate limiting e polish
- **Fase 7:** Piloto com tenants reais
